# =============================
# Pratibimb Modular Pipeline API
# =============================
# 
# This file contains 13 individual API endpoints that break down the full-braille-pipeline
# into discrete, manageable steps for better scalability and debugging.
#
# Each endpoint performs a specific task in the Braille conversion pipeline:
# 1. /validate-youtube-url - Validate YouTube URL
# 2. /download-video - Download video from YouTube
# 3. /extract-audio-transcript - Extract audio transcript
# 4. /extract-video-frames - Extract video frames
# 5. /deduplicate-frames - Remove duplicate frames
# 6. /generate-visual-descriptions - Generate descriptions for frames
# 7. /merge-audio-visual - Merge audio and visual transcripts
# 8. /rai-content-analysis - Responsible AI Content Analysis (block pipeline if unsafe)
# 9. /extract-visual-objects - Extract relevant visual objects
# 10. /enrich-with-figure-tags - Add figure tags to transcript
# 11. /generate-ascii-art - Generate ASCII art from objects
# 12. /generate-braille-art - Convert ASCII to Braille art
# 13. /assemble-final-document - Combine transcript with Braille art
# 14. /finalize-output - Generate final downloadable files

# --- Imports ---
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import logging
import os
import json
import uuid
import sys
import tempfile
import base64
import shutil
from datetime import datetime
from urllib.parse import urlparse, parse_qs

# --- Import Project Modules ---
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), "core"))
from core.youtube_analyzer import (
    download_video,
    get_audio_transcript,
    extract_frames,
    deduplicate_frames,
    generate_visual_descriptions,
    save_output,
    generate_merged_transcript,
    extract_relevant_visual_objects,
    enrich_transcript_with_figures
)

from core.braille_art import (
    generate_ascii_art_blocks,
    save_ascii_art_file,
    save_braille_art_file,
    convert_transcript_to_braille_with_art,
    convert_transcript_to_braille_with_art_from_content,
    convert_transcript_to_braille_with_art_telugu_from_content,
    convert_transcript_to_braille_with_art_kannada_from_content,
    generate_brf_file
)

# Import translation utils for translation step
from core.translation_utils import translate_figure_tagged_transcript_content

# --- RAI (Responsible AI) Integration ---
try:
    from RAI.rai_synthetic_data import SyntheticDataGenerator
    from RAI.rai_test_engine import RAITestEngine
    from RAI.rai_report_generator import RAIReportGenerator
    from RAI.rai_middleware import RAIContentAnalyzer
    RAI_AVAILABLE = True
    logging.info("âœ… RAI modules imported successfully")
except ImportError as e:
    RAI_AVAILABLE = False
    logging.warning(f"âš ï¸ RAI modules not available: {e}")

# --- Request Models ---
class BrailleLangRequest(BaseModel):
    transcript_content: str
    braille_art_content: str

class RAIAnalysisRequest(BaseModel):
    content: str
    analysis_type: str = "comprehensive"  # Options: "safety", "bias", "comprehensive"
    include_report: bool = True
    report_format: str = "html"  # Options: "html", "json"

# --- Load Config ---
CONFIG_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
    config = json.load(f)

# --- Config Values ---
yt_cfg = config['youtube_analyzer']
braille_cfg = config['braille_art']
request_files_cfg = config.get('request_files', {
    'folder': 'Request_files',
    'video_filename': 'downloaded_video.mp4',
    'audio_transcript_filename': 'audio_transcript.txt',
    'frames_dir': 'video_frames',
    'dedup_frames_dir': 'dedup_frames',
    'visual_description_filename': 'visual_description.txt'
})

# Ensure Request_files and subfolders exist
def ensure_request_files_structure():
    base = os.path.join(os.path.dirname(os.path.abspath(__file__)), request_files_cfg['folder'])
    os.makedirs(base, exist_ok=True)
    os.makedirs(os.path.join(base, request_files_cfg['frames_dir']), exist_ok=True)
    os.makedirs(os.path.join(base, request_files_cfg['dedup_frames_dir']), exist_ok=True)
    return base

ensure_request_files_structure()

# --- Logging Setup ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s %(message)s',
    handlers=[
        logging.FileHandler('logs/modular_pipeline.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# --- FastAPI App ---
app = FastAPI(title="Pratibimb Modular Pipeline API (Content-Based)", version="2.0.0")

# --- Marketplace Endpoints Router ---
from marketplace.marketplace_endpoints import router as marketplace_router
app.include_router(marketplace_router)

# --- CORS Setup ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Request Models ---
class YouTubeUrlRequest(BaseModel):
    youtube_url: str

class VideoContentRequest(BaseModel):
    video_content: str  # Base64 encoded video content
    video_title: str = "Video Content"

class AudioTranscriptRequest(BaseModel):
    youtube_url: str

class FrameExtractionRequest(BaseModel):
    video_content: str  # Base64 encoded video content

class DeduplicationRequest(BaseModel):
    frames_data: List[Dict[str, Any]]  # List of frame data with base64 content
    ssim_threshold: float = 0.95

class VisualDescriptionRequest(BaseModel):
    frames_data: List[Dict[str, Any]]  # List of frame data with base64 content
    video_title: str

class MergeTranscriptRequest(BaseModel):
    audio_transcript: str
    visual_description: str

class VisualObjectsRequest(BaseModel):
    audio_transcript: str
    visual_description: str

class EnrichTranscriptRequest(BaseModel):
    merged_transcript: str
    visual_objects: List[Dict[str, Any]]

class GenerateArtRequest(BaseModel):
    visual_objects: List[Dict[str, Any]]

class AssembleDocumentRequest(BaseModel):
    transcript_content: str
    braille_art_content: str

class FinalizeRequest(BaseModel):
    final_document: str
    ascii_art: str
    braille_art: str
    tagged_transcript: str

# --- Utility Functions ---
def get_video_id(youtube_url):
    """Extract video ID from YouTube URL"""
    parsed_url = urlparse(youtube_url)
    if 'youtube.com' in parsed_url.netloc:
        query = parse_qs(parsed_url.query)
        return query.get('v', [None])[0]
    elif 'youtu.be' in parsed_url.netloc:
        return parsed_url.path.lstrip('/')
    else:
        raise ValueError("Invalid YouTube URL format")

def create_temp_file(content: str, suffix: str = ".txt") -> str:
    """Create a temporary file with content and return the path"""
    with tempfile.NamedTemporaryFile(mode='w', suffix=suffix, delete=False, encoding='utf-8') as f:
        f.write(content)
        return f.name

def create_temp_binary_file(content: bytes, suffix: str = ".mp4") -> str:
    """Create a temporary binary file with content and return the path"""
    with tempfile.NamedTemporaryFile(mode='wb', suffix=suffix, delete=False) as f:
        f.write(content)
        return f.name

def cleanup_temp_file(file_path: str):
    """Remove temporary file"""
    try:
        if os.path.exists(file_path):
            os.unlink(file_path)
    except Exception as e:
        logging.warning(f"Failed to cleanup temp file {file_path}: {e}")

def encode_file_to_base64(file_path: str) -> str:
    """Encode file content to base64"""
    try:
        with open(file_path, 'rb') as f:
            return base64.b64encode(f.read()).decode('utf-8')
    except Exception as e:
        logging.error(f"Failed to encode file to base64: {e}")
        return ""

def decode_base64_to_bytes(encoded_content: str) -> bytes:
    """Decode base64 content to bytes"""
    try:
        return base64.b64decode(encoded_content)
    except Exception as e:
        logging.error(f"Failed to decode base64 content: {e}")
        return b""

# --- API Endpoints ---

@app.get("/")
async def root():
    """Root endpoint with API information"""
    return {
        "message": "Pratibimb Modular Pipeline API (Content-Based)",
        "version": "2.0.0",
        "total_steps": 14,
        "description": "Individual API endpoints for each step of the Braille conversion pipeline. Content-based - no file storage.",
        "endpoints": [
            "/validate-youtube-url",
            "/download-video",
            "/extract-audio-transcript",
            "/extract-video-frames",
            "/deduplicate-frames",
            "/generate-visual-descriptions",
            "/merge-audio-visual",
            "/rai-content-analysis",
            "/extract-visual-objects",
            "/enrich-with-figure-tags",
            "/generate-ascii-art",
            "/generate-braille-art",
            "/assemble-final-document",
            "/finalize-output"
        ],
        "rai_features": {
            "available": RAI_AVAILABLE,
            "description": "Comprehensive Responsible AI content analysis with safety checks, bias detection, and detailed reporting"
        }
    }

@app.post("/validate-youtube-url")
async def validate_youtube_url(request: YouTubeUrlRequest):
    """
    Validate YouTube URL format and accessibility
    """
    try:
        # Validate URL format
        video_id = get_video_id(request.youtube_url)
        if not video_id:
            raise ValueError("Invalid YouTube URL - could not extract video ID")
        
        logging.info(f"YouTube URL validated successfully - Video ID: {video_id}")
        
        return {
            "step": 1,
            "status": "success",
            "message": "ðŸ” YouTube URL validated successfully",
            "data": {
                "video_id": video_id,
                "original_url": request.youtube_url,
                "is_valid": True
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logging.error(f"URL validation failed: {str(e)}")
        return JSONResponse(
            status_code=400,
            content={
                "step": 1,
                "status": "error",
                "message": f"âŒ YouTube URL validation failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/download-video")
async def download_video_endpoint(request: YouTubeUrlRequest):
    """
    Download video from YouTube and save to Request_files, return only a success or error message.
    """
    try:
        logging.info(f"Starting video download from {request.youtube_url}")
        base = ensure_request_files_structure()
        video_path = os.path.join(base, request_files_cfg['video_filename'])
        # Download video
        video_path_result, video_title = download_video(request.youtube_url, video_path)
        if not video_path_result or not video_title:
            raise Exception("Video download failed - no file or title returned")
        logging.info(f"Video downloaded successfully - {video_title}")
        return {
            "step": 2,
            "status": "success",
            "message": f"ðŸ”„ Video downloaded successfully: {video_title}"
        }
    except Exception as e:
        logging.error(f"Video download failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "step": 2,
                "status": "error",
                "message": f"âŒ Video download failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/extract-audio-transcript")
async def extract_audio_transcript_endpoint(request: YouTubeUrlRequest):
    """
    Extract audio transcript from YouTube video, save to Request_files, and return transcript file and text.
    """
    try:
        logging.info("Extracting audio transcript")
        base = ensure_request_files_structure()
        video_path = os.path.join(base, request_files_cfg['video_filename'])
        transcript_path = os.path.join(base, request_files_cfg['audio_transcript_filename'])
        # Extract audio transcript
        audio_transcript = get_audio_transcript(request.youtube_url, video_path)
        # Save transcript to file
        with open(transcript_path, 'w', encoding='utf-8') as f:
            f.write(audio_transcript)
        logging.info("Audio transcript extracted and saved successfully")
        # Return transcript file as base64 and text
        transcript_b64 = encode_file_to_base64(transcript_path)
        return {
            "step": 3,
            "status": "success",
            "message": "ðŸ”Š Audio transcript extracted successfully",
            "data": {
                "transcript_file": transcript_b64,
                "transcript_content": audio_transcript,
                "filename": os.path.basename(transcript_path)
            }
        }
    except Exception as e:
        logging.error(f"Audio transcript extraction failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "step": 3,
                "status": "error",
                "message": f"âŒ Audio transcript extraction failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/extract-video-frames")
async def extract_video_frames_endpoint():
    """
    Extract frames from video in Request_files and return only a success message and frame count.
    """
    try:
        logging.info("Extracting video frames from Request_files video")
        base = ensure_request_files_structure()
        video_path = os.path.join(base, request_files_cfg['video_filename'])
        frames_dir = os.path.join(base, request_files_cfg['frames_dir'])
        import shutil
        if os.path.exists(frames_dir):
            shutil.rmtree(frames_dir)
        os.makedirs(frames_dir, exist_ok=True)
        extract_frames(video_path, frames_dir)
        frame_files = sorted([f for f in os.listdir(frames_dir) if f.endswith('.jpg')])
        frame_count = len(frame_files)
        logging.info(f"{frame_count} frames extracted successfully and saved to {frames_dir}")
        return {
            "step": 4,
            "status": "success",
            "message": f"ðŸ–¼ï¸ {frame_count} video frames extracted successfully",
            "data": {
                "frame_count": frame_count
            }
        }
    except Exception as e:
        logging.error(f"Video frame extraction failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "step": 4,
                "status": "error",
                "message": f"âŒ Video frame extraction failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/deduplicate-frames")
async def deduplicate_frames_endpoint():
    """
    Remove duplicate frames using SSIM similarity and save unique frames to Request_files. Return only a success message and count.
    """
    try:
        logging.info("Deduplicating frames using SSIM in Request_files")
        base = ensure_request_files_structure()
        frames_dir = os.path.join(base, request_files_cfg['frames_dir'])
        dedup_dir = os.path.join(base, request_files_cfg['dedup_frames_dir'])
        import shutil
        if os.path.exists(dedup_dir):
            shutil.rmtree(dedup_dir)
        os.makedirs(dedup_dir, exist_ok=True)
        unique_frame_paths = deduplicate_frames(frames_dir, request_files_cfg.get('ssim_threshold', 0.95))
        unique_count = len(unique_frame_paths) if unique_frame_paths else 0
        if not unique_frame_paths:
            return {
                "step": 5,
                "status": "warning",
                "message": "âš ï¸ No visually distinct scenes found after deduplication",
                "data": {
                    "unique_count": 0
                }
            }
        for frame_path in unique_frame_paths:
            dest_path = os.path.join(dedup_dir, os.path.basename(frame_path))
            shutil.copy2(frame_path, dest_path)
        logging.info(f"{unique_count} unique frames identified and saved to {dedup_dir}")
        return {
            "step": 5,
            "status": "success",
            "message": f"ðŸ§¹ {unique_count} unique frames identified after deduplication",
            "data": {
                "unique_count": unique_count
            }
        }
    except Exception as e:
        logging.error(f"Frame deduplication failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "step": 5,
                "status": "error",
                "message": f"âŒ Frame deduplication failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/generate-visual-descriptions")
async def generate_visual_descriptions_endpoint():
    """
    Generate visual descriptions for deduplicated frames in Request_files and respond as file and its content as string.
    """
    try:
        logging.info("Generating visual descriptions using BLIP model from Request_files")
        base = ensure_request_files_structure()
        dedup_dir = os.path.join(base, request_files_cfg['dedup_frames_dir'])
        visual_desc_path = os.path.join(base, request_files_cfg['visual_description_filename'])
        frame_files = sorted([f for f in os.listdir(dedup_dir) if f.endswith('.jpg')])
        if not frame_files:
            return {
                "step": 6,
                "status": "warning",
                "message": "âš ï¸ No frames available for visual description",
                "data": {
                    "description_content": "No visually distinct scenes found.",
                    "descriptions_count": 0
                }
            }
        frame_paths = [os.path.join(dedup_dir, f) for f in frame_files]
        from transformers import BlipProcessor, BlipForConditionalGeneration
        import torch
        blip_processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
        blip_model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        blip_model.to(device)
        visual_descriptions = generate_visual_descriptions(
            frame_paths, "", blip_model, blip_processor, device
        )
        description_content = "\n\n".join(visual_descriptions)
        with open(visual_desc_path, 'w', encoding='utf-8') as f:
            f.write(description_content)
        desc_b64 = encode_file_to_base64(visual_desc_path)
        logging.info(f"Visual descriptions generated for {len(frame_paths)} frames and saved to {visual_desc_path}")
        return {
            "step": 6,
            "status": "success",
            "message": f"ðŸ“ Visual descriptions generated for {len(frame_paths)} frames",
            "data": {
                "description_file": desc_b64,
                "description_content": description_content,
                "filename": os.path.basename(visual_desc_path)
            }
        }
    except Exception as e:
        logging.error(f"Visual description generation failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "step": 6,
                "status": "error",
                "message": f"âŒ Visual description generation failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/merge-audio-visual")
async def merge_audio_visual_endpoint(request: MergeTranscriptRequest):
    """
    Merge audio transcript and visual descriptions and return merged content
    """
    try:
        logging.info("Merging audio transcript and visual descriptions")
        
        if not request.audio_transcript or not request.visual_description:
            raise ValueError("Both audio transcript and visual description are required")
        
        # Generate merged transcript
        merged_transcript = generate_merged_transcript(request.audio_transcript, request.visual_description)
        
        logging.info("Merged transcript generated successfully")
        
        # Attempt to delete Request_files folder after success
        try:
            base = os.path.join(os.path.dirname(os.path.abspath(__file__)), request_files_cfg['folder'])
            import shutil
            if os.path.exists(base):
                shutil.rmtree(base)
                logging.info(f"Request_files folder deleted after merge-audio-visual step.")
        except Exception as cleanup_err:
            logging.warning(f"Failed to cleanup Request_files after merge-audio-visual: {cleanup_err}")

        return {
            "step": 7,
            "status": "success",
            "message": "ðŸ”— Audio and visual transcripts merged successfully",
            "data": {
                "merged_transcript": merged_transcript,
                "merged_length": len(merged_transcript),
                "preview": merged_transcript[:300] + "..." if len(merged_transcript) > 300 else merged_transcript
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logging.error(f"Audio-visual merge failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "step": 7,
                "status": "error",
                "message": f"âŒ Audio-visual merge failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/extract-visual-objects")
async def extract_visual_objects_endpoint(request: VisualObjectsRequest):
    """
    Extract relevant visual objects from transcripts and return as JSON data
    """
    try:
        logging.info("Extracting relevant visual objects")
        
        if not request.audio_transcript or not request.visual_description:
            raise ValueError("Both audio transcript and visual description are required")
        
        # Extract visual objects
        visual_objects = extract_relevant_visual_objects(request.audio_transcript, request.visual_description)
        
        logging.info(f"{len(visual_objects)} visual objects extracted successfully")
        
        return {
            "step": 8,
            "status": "success",
            "message": f"ðŸ” {len(visual_objects)} relevant visual objects extracted",
            "data": {
                "visual_objects": visual_objects,
                "objects_count": len(visual_objects),
                "objects_preview": visual_objects[:3] if len(visual_objects) > 3 else visual_objects
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logging.error(f"Visual objects extraction failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "step": 8,
                "status": "error",
                "message": f"âŒ Visual objects extraction failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/enrich-with-figure-tags")
async def enrich_with_figure_tags_endpoint(request: EnrichTranscriptRequest):
    """
    Enrich transcript with figure tags and return enriched content (NO temp files, only payload)
    """
    try:
        logging.info("Enriching transcript with figure tags (payload only, no temp files)")
        if not request.merged_transcript or request.visual_objects is None:
            raise ValueError("Both merged transcript and visual objects are required")

        # Use the payload directly: merged_transcript (str), visual_objects (list/dict)
        transcript_str = request.merged_transcript
        # Accept both list/dict or JSON string for visual_objects
        if isinstance(request.visual_objects, str):
            objects_json = request.visual_objects
        else:
            objects_json = json.dumps(request.visual_objects)

        # Enrich transcript with figure tags (pass strings, not file paths)
        enriched_content = enrich_transcript_with_figures(transcript_str, objects_json)

        logging.info("Transcript enriched with figure tags successfully (no temp files)")
        return {
            "step": 9,
            "status": "success",
            "message": "ðŸ·ï¸ Transcript enriched with figure tags successfully",
            "data": {
                "enriched_transcript": enriched_content,
                "content_length": len(enriched_content),
                "preview": enriched_content[:300] + "..." if len(enriched_content) > 300 else enriched_content
            },
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logging.error(f"Figure tag enrichment failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "step": 9,
                "status": "error",
                "message": f"âŒ Figure tag enrichment failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/generate-ascii-art")
async def generate_ascii_art_endpoint(request: GenerateArtRequest):
    """
    Generate ASCII art from visual objects and return art content
    """
    try:
        logging.info("Generating ASCII art from visual objects")
        
        # Handle empty visual objects gracefully
        if not request.visual_objects or len(request.visual_objects) == 0:
            logging.info("No visual objects provided, returning empty ASCII art result")
            return {
                "step": 10,
                "status": "success",
                "message": "âš ï¸ No visual objects available for ASCII art generation",
                "data": {
                    "ascii_art_content": "",
                    "ascii_results": {},
                    "art_blocks_count": 0,
                    "objects_processed": 0
                },
                "timestamp": datetime.now().isoformat()
            }
        
        # Generate ASCII art
        ascii_results = generate_ascii_art_blocks(request.visual_objects)
        
        if not ascii_results:
            logging.warning("No ASCII art was generated")
            return {
                "step": 10,
                "status": "warning",
                "message": "âš ï¸ No ASCII art was generated. Check Gemini API configuration.",
                "data": {
                    "ascii_art_content": "",
                    "ascii_results": {},
                    "art_blocks_count": 0,
                    "objects_processed": len(request.visual_objects)
                },
                "timestamp": datetime.now().isoformat()
            }
        
        # Convert ASCII results to string format
        ascii_content_lines = []
        for fig_id, art_data in ascii_results.items():
            ascii_content_lines.append(f"ID: {fig_id}")
            ascii_content_lines.append("ASCII ART:")
            ascii_content_lines.append(art_data.get('ascii_art', ''))
            ascii_content_lines.append("---")
        
        ascii_content = "\n".join(ascii_content_lines)
        
        logging.info(f"ASCII art generated for {len(ascii_results)} objects")
        
        return {
            "step": 10,
            "status": "success",
            "message": f"ðŸŽ¨ ASCII art generated for {len(ascii_results)} objects",
            "data": {
                "ascii_art_content": ascii_content,
                "ascii_results": ascii_results,
                "art_blocks_count": len(ascii_results),
                "objects_processed": len(request.visual_objects)
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logging.error(f"ASCII art generation failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "step": 10,
                "status": "error",
                "message": f"âŒ ASCII art generation failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/generate-braille-art")
async def generate_braille_art_endpoint(request: GenerateArtRequest):
    """
    Convert ASCII art to Braille art and return braille content
    """
    try:
        logging.info("Converting ASCII art to Braille art")
        
        # Handle empty visual objects gracefully
        if not request.visual_objects or len(request.visual_objects) == 0:
            logging.info("No visual objects provided, returning empty Braille art result")
            return {
                "step": 11,
                "status": "success",
                "message": "âš ï¸ No visual objects available for Braille art generation",
                "data": {
                    "braille_art_content": "",
                    "ascii_results": {},
                    "conversion_completed": True
                },
                "timestamp": datetime.now().isoformat()
            }
        
        # Generate ASCII results first (needed for Braille conversion)
        ascii_results = generate_ascii_art_blocks(request.visual_objects)
        
        if not ascii_results:
            logging.warning("No ASCII art available for Braille conversion")
            return {
                "step": 11,
                "status": "warning",
                "message": "âš ï¸ No ASCII art available for Braille conversion",
                "data": {
                    "braille_art_content": "",
                    "ascii_results": {},
                    "conversion_completed": True
                },
                "timestamp": datetime.now().isoformat()
            }
        
        # Convert to braille using the core function
        from core.braille_art import ascii_art_to_braille
        
        braille_content_lines = []
        for fig_id, art_data in ascii_results.items():
            ascii_art = art_data.get('ascii_art', '')
            if ascii_art:
                braille_art = ascii_art_to_braille(ascii_art)
                braille_content_lines.append(f"ID: {fig_id}")
                braille_content_lines.append("BRAILLE ART:")
                braille_content_lines.append(braille_art)
                braille_content_lines.append("---")
        
        braille_content = "\n".join(braille_content_lines)
        
        logging.info(f"Braille art generated for {len(ascii_results)} objects")
        
        return {
            "step": 11,
            "status": "success",
            "message": "â ƒ ASCII art converted to Braille art successfully",
            "data": {
                "braille_art_content": braille_content,
                "ascii_results": ascii_results,
                "conversion_completed": True
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logging.error(f"Braille art generation failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "step": 11,
                "status": "error",
                "message": f"âŒ Braille art generation failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/generate-braille-text")
async def generate_braille_text_endpoint(request: AssembleDocumentRequest):
    """
    Assemble final Braille document with text and art and return final content
    """
    try:
        logging.info("Assembling final Braille document")
        
        if not request.transcript_content or not request.braille_art_content:
            raise ValueError("Both transcript content and braille art content are required")
        
        # Use the content-based conversion function
        final_braille_content = convert_transcript_to_braille_with_art_from_content(
            request.transcript_content, 
            request.braille_art_content
        )
        final_braille_content = generate_brf_file(final_braille_content)
        file_size = len(final_braille_content.encode('utf-8'))
        
        logging.info("Final Braille document assembled successfully")
        
        return {
            "step": 12,
            "status": "success",
            "message": "ðŸ“¦ Final Braille document assembled successfully",
            "data": {
                "final_braille_content": final_braille_content,
                "file_size": file_size,
                "contains_text": True,
                "contains_art": True,
                "preview": final_braille_content[:300] + "..." if len(final_braille_content) > 300 else final_braille_content
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logging.error(f"Final document assembly failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "step": 12,
                "status": "error",
                "message": f"âŒ Final document assembly failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/combine-braille-text-and-art")
async def combine_braille_text_and_art_endpoint(request: FinalizeRequest):
    """
    Finalize output and prepare all downloadable content
    """
    try:
        logging.info("Finalizing output and preparing downloadable content")
        
        # Prepare all file contents
        available_files = []
        
        if request.final_document:
            available_files.append({
                "name": "Final Braille Transcript",
                "content": request.final_document,
                "size": len(request.final_document.encode('utf-8')),
                "type": "text/plain; charset=utf-8"
            })
        
        if request.tagged_transcript:
            available_files.append({
                "name": "Figure-Tagged Transcript",
                "content": request.tagged_transcript,
                "size": len(request.tagged_transcript.encode('utf-8')),
                "type": "text/plain; charset=utf-8"
            })
        
        if request.braille_art:
            available_files.append({
                "name": "Braille Art",
                "content": request.braille_art,
                "size": len(request.braille_art.encode('utf-8')),
                "type": "text/plain; charset=utf-8"
            })
        
        if request.ascii_art:
            available_files.append({
                "name": "ASCII Art",
                "content": request.ascii_art,
                "size": len(request.ascii_art.encode('utf-8')),
                "type": "text/plain; charset=utf-8"
            })
        
        logging.info("Output finalization completed")
        
        return {
            "step": 13,
            "status": "success",
            "message": "âœ… Braille conversion pipeline completed successfully!",
            "data": {
                "available_files": available_files,
                "total_files": len(available_files),
                "pipeline_completed": True,
                "ready_for_download": len(available_files) > 0
            },
            "summary": {
                "process": "Full Braille conversion pipeline",
                "total_steps": 13,
                "status": "completed",
                "files_generated": len(available_files)
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logging.error(f"Output finalization failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "step": 13,
                "status": "error",
                "message": f"âŒ Output finalization failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )
    
    # --- Braille in Telugu Endpoint ---
@app.post("/braille-in-telugu")
async def braille_in_telugu_endpoint(request: BrailleLangRequest):
    """
    Translate transcript to Telugu and generate final Telugu Braille document (content-based, no files).
    """
    try:
        logging.info("Translating transcript to Telugu and generating Braille (content-based)")
        if not request.transcript_content or not request.braille_art_content:
            raise ValueError("Both transcript content and braille art content are required")

        # Step 1: Translate transcript to Telugu (preserving figure tags)
        translations = translate_figure_tagged_transcript_content(request.transcript_content, lang_map={'te': 'Telugu'})
        telugu_transcript = translations.get('te', None)
        if not telugu_transcript or telugu_transcript.strip().startswith('[Translation failed'):
            raise ValueError("Telugu translation failed or not available")

        # Step 2: Generate final Telugu Braille document (content-based)
        final_braille_content = convert_transcript_to_braille_with_art_telugu_from_content(
            telugu_transcript,
            request.braille_art_content
        )
        final_braille_content = generate_brf_file(final_braille_content)
        if not final_braille_content:
            raise ValueError("Failed to generate Telugu Braille content")

        file_size = len(final_braille_content.encode('utf-8'))
        logging.info("Telugu Braille document generated successfully")
        return {
            "status": "success",
            "message": "ðŸŸ£ Telugu Braille document generated successfully",
            "data": {
                "telugu_braille_content": final_braille_content,
                "telugu_transcript": telugu_transcript,
                "file_size": file_size,
                "contains_text": True,
                "contains_art": True,
                "preview": final_braille_content[:300] + "..." if len(final_braille_content) > 300 else final_braille_content
            },
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logging.error(f"Telugu Braille generation failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": f"âŒ Telugu Braille generation failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )

# --- Braille in Kannada Endpoint ---
@app.post("/braille-in-kannada")
async def braille_in_kannada_endpoint(request: BrailleLangRequest):
    """
    Translate transcript to Kannada and generate final Kannada Braille document (content-based, no files).
    """
    try:
        logging.info("Translating transcript to Kannada and generating Braille (content-based)")
        if not request.transcript_content or not request.braille_art_content:
            raise ValueError("Both transcript content and braille art content are required")

        # Step 1: Translate transcript to Kannada (preserving figure tags)
        translations = translate_figure_tagged_transcript_content(request.transcript_content, lang_map={'kn': 'Kannada'})
        kannada_transcript = translations.get('kn', None)
        if not kannada_transcript or kannada_transcript.strip().startswith('[Translation failed'):
            raise ValueError("Kannada translation failed or not available")

        # Step 2: Generate final Kannada Braille document (content-based)
        final_braille_content = convert_transcript_to_braille_with_art_kannada_from_content(
            kannada_transcript,
            request.braille_art_content
        )
        final_braille_content = generate_brf_file(final_braille_content)
        if not final_braille_content:
            raise ValueError("Failed to generate Kannada Braille content")

        file_size = len(final_braille_content.encode('utf-8'))
        logging.info("Kannada Braille document generated successfully")
        return {
            "status": "success",
            "message": "ðŸŸ¢ Kannada Braille document generated successfully",
            "data": {
                "kannada_braille_content": final_braille_content,
                "kannada_transcript": kannada_transcript,
                "file_size": file_size,
                "contains_text": True,
                "contains_art": True,
                "preview": final_braille_content[:300] + "..." if len(final_braille_content) > 300 else final_braille_content
            },
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logging.error(f"Kannada Braille generation failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": f"âŒ Kannada Braille generation failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )


# --- RAI Content Analysis Endpoint ---

@app.post("/rai-content-analysis")
async def rai_content_analysis(request: RAIAnalysisRequest):
    """
    Comprehensive Responsible AI content analysis with safety checks, bias detection, and reporting.
    
    This endpoint performs complete RAI analysis including:
    - Content safety (toxicity, hate speech, violence)
    - Bias detection (demographic, linguistic, cultural)
    - Privacy protection (PII detection)
    - Sentiment analysis
    - Generates downloadable HTML reports with detailed analytics
    
    Returns:
    - Analysis verdict (safe/unsafe/warning)
    - Detailed analysis results
    - Risk assessment
    - Downloadable HTML report (if requested)
    """
    try:
        if not RAI_AVAILABLE:
            return JSONResponse(
                status_code=503,
                content={
                    "status": "error",
                    "message": "âŒ RAI services are not available. Please install RAI dependencies.",
                    "timestamp": datetime.now().isoformat()
                }
            )
        
        if not request.content or not request.content.strip():
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": "âŒ Content cannot be empty for RAI analysis",
                    "timestamp": datetime.now().isoformat()
                }
            )
        
        logging.info(f"Starting RAI content analysis for {len(request.content)} characters")
        analysis_start_time = datetime.now()
        
        # Load RAI configuration
        rai_config_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'RAI', 'rai_config.json')
        if os.path.exists(rai_config_path):
            with open(rai_config_path, 'r', encoding='utf-8') as f:
                rai_config = json.load(f)
        else:
            # Use default configuration
            rai_config = {
                "enabled": True,
                "rai_settings": {
                    "enabled": True,
                    "mode": "development",
                    "strict_mode": False
                },
                "content_filters": {
                    "toxicity": {"enabled": True, "threshold": 0.8, "action": "warn"},
                    "hate_speech": {"enabled": True, "threshold": 0.7, "action": "warn"},
                    "bias": {"enabled": True, "threshold": 0.6, "action": "warn"}
                }
            }
        
        # Initialize RAI components
        analyzer = RAIContentAnalyzer(rai_config)
        
        # Perform comprehensive content analysis
        content_analysis = await analyzer.analyze_content(request.content, "user_input")
        
        # Generate test data for comprehensive reporting
        synthetic_generator = SyntheticDataGenerator(rai_config)
        
        # Create a single test case with the user's content
        test_data = {
            "user_content_analysis": {
                "content": request.content[:200] + "..." if len(request.content) > 200 else request.content,
                "analysis": content_analysis,
                "timestamp": analysis_start_time.isoformat(),
                "content_length": len(request.content)
            }
        }
        
        # Determine overall verdict
        verdict = "SAFE"
        risk_level = content_analysis.get("risk_level", "low")
        is_blocked = content_analysis.get("blocked", False)
        has_warnings = len(content_analysis.get("warnings", [])) > 0
        
        if is_blocked:
            verdict = "UNSAFE"
        elif has_warnings or risk_level == "medium":
            verdict = "WARNING"
        elif risk_level == "high":
            verdict = "UNSAFE"
        
        # Generate HTML report if requested
        html_report_content = None
        html_report_b64 = None
        report_filename = None
        
        if request.include_report and request.report_format == "html":
            try:
                report_generator = RAIReportGenerator(rai_config)
                
                # Create synthetic data stats for the report
                synthetic_stats = {
                    "total_samples": 1,
                    "categories": {
                        "user_content": 1
                    },
                    "generation_time": 0.1,
                    "diversity_metrics": {
                        "content_types": ["user_input"],
                        "analysis_depth": "comprehensive"
                    }
                }
                
                # Create test results structure for the report
                test_results = {
                    "session_id": str(uuid.uuid4()),
                    "start_time": analysis_start_time.isoformat(),
                    "config": rai_config,
                    "results": {
                        "content_analysis": [test_data["user_content_analysis"]],
                        "safety_tests": [],
                        "bias_tests": [],
                        "performance_tests": []
                    },
                    "metrics": {
                        "total_tests": 1,
                        "passed_tests": 1 if verdict == "SAFE" else 0,
                        "failed_tests": 1 if verdict == "UNSAFE" else 0,
                        "warning_tests": 1 if verdict == "WARNING" else 0,
                        "overall_score": 0.9 if verdict == "SAFE" else 0.5 if verdict == "WARNING" else 0.1
                    },
                    "summary": {
                        "verdict": verdict,
                        "risk_level": risk_level,
                        "analysis_duration": (datetime.now() - analysis_start_time).total_seconds(),
                        "content_analyzed": len(request.content)
                    }
                }
                
                # Create middleware metrics for the report
                middleware_metrics = {
                    "total_requests": 1,
                    "blocked_requests": 1 if is_blocked else 0,
                    "warned_requests": 1 if has_warnings else 0,
                    "avg_response_time": (datetime.now() - analysis_start_time).total_seconds(),
                    "risk_distribution": {
                        "low": 1 if risk_level == "low" else 0,
                        "medium": 1 if risk_level == "medium" else 0,
                        "high": 1 if risk_level == "high" else 0
                    }
                }
                
                # Generate the report
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                report_filename = f"rai_content_analysis_report_{timestamp}.html"
                
                # Ensure rai_reports directory exists
                reports_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "rai_reports")
                os.makedirs(reports_dir, exist_ok=True)
                
                report_path = os.path.join(reports_dir, report_filename)
                
                html_report_path = report_generator.generate_comprehensive_report(
                    test_results=test_results,
                    synthetic_data_stats=synthetic_stats,
                    middleware_metrics=middleware_metrics,
                    output_path=report_path
                )
                
                # Read the generated HTML report and encode to base64
                if os.path.exists(html_report_path):
                    with open(html_report_path, 'rb') as f:
                        html_report_content = f.read()
                        html_report_b64 = base64.b64encode(html_report_content).decode('utf-8')
                    
                    logging.info(f"HTML report generated: {html_report_path}")
                else:
                    logging.warning("HTML report generation failed - file not found")
                    
            except Exception as report_error:
                logging.error(f"Failed to generate HTML report: {report_error}")
                # Continue without report - don't fail the whole analysis
        
        # Prepare response
        analysis_duration = (datetime.now() - analysis_start_time).total_seconds()
        # Improved, more meaningful and punctuated message
        if is_blocked or verdict == "UNSAFE":
            main_message = "ðŸš« Content blocked by Responsible AI analysis. Please review the detailed report."
            status_val = "blocked"
        elif verdict == "WARNING":
            main_message = f"âš ï¸ Responsible AI Content Analysis completed with warnings. Verdict: {verdict}."
            status_val = "success"
        else:
            main_message = f"âœ… Responsible AI Content Analysis completed. Verdict: {verdict}."
            status_val = "success"

        response_data = {
            "status": status_val,
            "verdict": verdict,
            "message": main_message,
            "analysis": {
                "content_length": len(request.content),
                "analysis_type": request.analysis_type,
                "risk_level": risk_level,
                "blocked": is_blocked,
                "warnings_count": len(content_analysis.get("warnings", [])),
                "safety_scores": content_analysis.get("safety_scores", {}),
                "bias_indicators": content_analysis.get("bias_indicators", {}),
                "sentiment": content_analysis.get("sentiment", {}),
                "recommendations": content_analysis.get("recommendations", []),
                "analysis_duration_seconds": analysis_duration
            },
            "detailed_results": content_analysis,
            "timestamp": datetime.now().isoformat()
        }
        # Add report information if generated
        if html_report_b64 and request.include_report:
            response_data["report"] = {
                "format": "html",
                "filename": report_filename,
                "content": html_report_b64,
                "size_bytes": len(html_report_content) if html_report_content else 0,
                "download_instructions": "Decode the base64 content and save as .html file to view the report"
            }
        # Add warnings to response if any
        if content_analysis.get("warnings"):
            response_data["warnings"] = content_analysis["warnings"]
        logging.info(f"RAI analysis completed in {analysis_duration:.2f}s - Verdict: {verdict}")
        return response_data
        
    except Exception as e:
        logging.error(f"RAI content analysis failed: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": f"âŒ RAI content analysis failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        )


# --- Health Check Endpoints ---

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "Pratibimb Modular Pipeline API (Content-Based)",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/status")
async def status_check():
    """Status check with system information"""
    return {
        "status": "operational",
        "service": "Pratibimb Modular Pipeline API (Content-Based)",
        "version": "2.0.0",
        "total_steps": 13,
        "mode": "content-based",
        "features": [
            "No local file storage",
            "Content-based requests/responses",
            "Base64 encoded file transfers",
            "Temporary file handling"
        ],
        "timestamp": datetime.now().isoformat()
    }

if __name__ == "__main__":
    import uvicorn
    print("ðŸŒŸ PRATIBIMB - Modular Pipeline API Server (Content-Based) ðŸŒŸ")
    print("==================================================================")
    print("ðŸ“ Server will be available at: http://localhost:8001")
    print("ðŸ“– API Documentation: http://localhost:8001/docs")
    print("ðŸ”§ Individual step endpoints available:")
    print("   â€¢ POST /validate-youtube-url")
    print("   â€¢ POST /download-video") 
    print("   â€¢ POST /extract-audio-transcript")
    print("   â€¢ POST /extract-video-frames")
    print("   â€¢ POST /deduplicate-frames")
    print("   â€¢ POST /generate-visual-descriptions")
    print("   â€¢ POST /merge-audio-visual")
    print("   â€¢ POST /extract-visual-objects")
    print("   â€¢ POST /enrich-with-figure-tags")
    print("   â€¢ POST /generate-ascii-art")
    print("   â€¢ POST /generate-braille-art")
    print("   â€¢ POST /assemble-final-document")
    print("   â€¢ POST /finalize-output")
    print("==================================================================")
    print("ðŸ“‹ Content-Based Features:")
    print("   â€¢ No local file storage")
    print("   â€¢ Content passed in request body")
    print("   â€¢ Files returned as content in response")
    print("   â€¢ Base64 encoding for binary data")
    print("   â€¢ Temporary file handling only")
    print("==================================================================")
    print("Press Ctrl+C to stop the server")
    print()
    
    uvicorn.run(app, host="0.0.0.0", port=8001, reload=False)
